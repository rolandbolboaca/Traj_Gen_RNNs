{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f836939",
   "metadata": {},
   "source": [
    "#### Functions Group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db654c2",
   "metadata": {},
   "source": [
    "##### **Module Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a59ced3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 09:05:02.883701: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749708302.989223 1079963 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749708303.017371 1079963 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749708303.262133 1079963 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749708303.262157 1079963 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749708303.262158 1079963 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749708303.262159 1079963 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-12 09:05:03.289788: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/roland/traj_exp/venv/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# oneDNN warning suppression TF 2.4.1\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "from ipywidgets import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import energy_distance, wasserstein_distance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from math import radians\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ee72ba",
   "metadata": {},
   "source": [
    "##### **Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe4066cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED = 837\n",
    "\n",
    "SEED = 42\n",
    "TESTING_SIZE = 0.2\n",
    "VALIDATION_SIZE = 0.1\n",
    "\n",
    "# Total number of trajectories. If set to 0, all trajectories are used\n",
    "TOTAL_TRAJS = 1000\n",
    "\n",
    "TRAINING_TESTING_SAME_FILE = True\n",
    "\n",
    "# SELECTED_DATASET = \"SANFRANCISCO\" \n",
    "SELECTED_DATASET = \"PORTO\"  \n",
    "\n",
    "\n",
    "DATASET = {\"PORTO\": \"datasets/Porto/porto_uci_31k_traj_drop_only.pkl\",\n",
    "           \"SANFRANCISCO\": \"datasets/San_Francisco/train_trajectories.pkl\"}\n",
    "\n",
    "TESTING_FILE = None\n",
    "\n",
    "COLUMNS = [\"lat\", \"lon\"]\n",
    "\n",
    "DATA_SQUARE_SF = { \n",
    "                \"lon_1\": 37.86499,\n",
    "                \"lat_1\": -122.53304,\n",
    "                \"lon_2\": 37.68481,\n",
    "                \"lat_2\": -122.30576\n",
    "                }\n",
    "\n",
    "DATA_SQUARE_PORTO = { \n",
    "                \"lon_1\": 41.23969,\n",
    "                \"lat_1\": -8.73005,\n",
    "                \"lon_2\": 41.05951,\n",
    "                \"lat_2\": -8.49195\n",
    "                }\n",
    "\n",
    "DATA_SQUARE = {\"SANFRANCISCO\": DATA_SQUARE_SF,\n",
    "               \"PORTO\": DATA_SQUARE_PORTO}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b15025a",
   "metadata": {},
   "source": [
    "##### **Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "223ce641",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_CELLS = 16 #32\n",
    "SEQ_LEN = 25 #25\n",
    "BATCH_SIZE = 16 #32\n",
    "EPOCHS = 100\n",
    "LR = 0.01\n",
    "\n",
    "STATEFUL = False\n",
    "RETURN_SEQ = True\n",
    "\n",
    "NUM_FEATS = 2\n",
    "NUM_OUTPUTS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024d331c",
   "metadata": {},
   "source": [
    "##### **Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10dcb344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(data, data_path):\n",
    "    \"\"\" Save data to a pickle file \"\"\"\n",
    "    \n",
    "    with open(data_path, 'wb') as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2472c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(data_path):\n",
    "    \"\"\" Load data from file path\"\"\"\n",
    "    \n",
    "    with open(data_path, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ec37b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_pickle(data_path, num_of_traj = 0):\n",
    "    \"\"\" Load data from pickle file \"\"\"\n",
    "    \n",
    "    df = load_pickle(data_path)\n",
    "    \n",
    "    if num_of_traj == 0:\n",
    "        num_of_traj = len(df)\n",
    "        \n",
    "    df = df[:num_of_traj]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74c4b134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_Y_from_data(data, num_of_traj):\n",
    "    \"\"\"\n",
    "        Create X and Y from the data.\n",
    "        X is composed of the trajectory data starting from the first point to the second last point\n",
    "        Y is composed of the trajectory data starting from the second point to the last point\n",
    "        Keeps only the selected COLUMNS (defined in the parameters block)\n",
    "    \"\"\"\n",
    "    X, Y = [0.0]  * num_of_traj, [0.0] * num_of_traj\n",
    "\n",
    "\n",
    "    for i in range(num_of_traj):\n",
    "        # X is composed of the trajectory data starting from the first point to the second last point\n",
    "        X[i] =  data[i][COLUMNS].iloc[0:-1] \n",
    "        X[i].columns = COLUMNS\n",
    "\n",
    "        # Y is composed of the trajectory data starting from the second point to the last point\n",
    "        Y[i] =  data[i][COLUMNS].iloc[1:] \n",
    "        Y[i].columns = COLUMNS\n",
    "        \n",
    "        X[i] = X[i].to_numpy()\n",
    "        Y[i] = Y[i].to_numpy()\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de160d9",
   "metadata": {},
   "source": [
    "##### **Data preprocessing, Normalization and Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32799f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_in_square(data, square):\n",
    "    \"\"\" Get data inside the square defined by the square dictionary \"\"\" \n",
    "    \n",
    "    # Ensure correct bounds regardless of coordinate sign or order\n",
    "    lat_min = min(square[\"lat_1\"], square[\"lat_2\"])\n",
    "    lat_max = max(square[\"lat_1\"], square[\"lat_2\"])\n",
    "    lon_min = min(square[\"lon_1\"], square[\"lon_2\"])\n",
    "    lon_max = max(square[\"lon_1\"], square[\"lon_2\"])\n",
    "\n",
    "    filtered_data = []\n",
    "    \n",
    "    for traj in data:\n",
    "        in_lat_bounds = traj[\"lat\"].between(lat_min, lat_max)\n",
    "        in_lon_bounds = traj[\"lon\"].between(lon_min, lon_max)\n",
    "\n",
    "        if (in_lat_bounds & in_lon_bounds).all():\n",
    "            filtered_data.append(traj)\n",
    "            \n",
    "            \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd6d9208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max_from_data(data):\n",
    "    # Get trajectories min and max values\n",
    "    num_of_traj = len(data)\n",
    "    mins, maxs = [0.0] * num_of_traj, [0.0] * num_of_traj\n",
    "\n",
    "    for i in range(num_of_traj):\n",
    "        mins[i]  = np.array(data[i].min()) \n",
    "        maxs[i] = np.array(data[i].max()) \n",
    "\n",
    "    mins =  np.min( np.array(mins), axis = 0)[0 : 2]\n",
    "    maxs =  np.max( np.array(maxs), axis = 0)[0 : 2]\n",
    "    \n",
    "    return mins, maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96321ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(dataset, \n",
    "                   normalization_type = 'min-max',\n",
    "                   normalization_ranges = None,\n",
    "                   testing_data_norm = False):\n",
    "    \"\"\"\n",
    "        Function to normalize the dataset using either min-max or standard normalization.\n",
    "        Can be used for separate testing data normalization or for normalization of the whole dataset with other ranges.\n",
    "        Returns the normalized dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    if normalization_type == 'min-max':   \n",
    "        scaler = MinMaxScaler()\n",
    "    elif normalization_type == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    \n",
    "    # Normalize the dataset using the ranges given in normalization_ranges (min and max)        \n",
    "    # Used for separate testing data normalization or for normalization of the whole dataset with other ranges\n",
    "    \n",
    "    if normalization_ranges is not None:\n",
    "        scaler.min = normalization_ranges[\"min\"]\n",
    "        scaler.max = normalization_ranges[\"max\"]\n",
    "    else:\n",
    "        scaler.fit(dataset)\n",
    "        \n",
    "    columns = dataset.columns\n",
    "    \n",
    "    norm_dataset = scaler.transform(dataset)\n",
    "    norm_dataset = pd.DataFrame(norm_dataset, columns = columns)\n",
    "    \n",
    "    return scaler, norm_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "259e2608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_trajectory_data(dataset, \n",
    "                   normalization_type = 'min-max',\n",
    "                   normalization_ranges = None,\n",
    "                   testing_data_norm = False,\n",
    "                   scaler = None):\n",
    "    \"\"\"\n",
    "        Function to normalize the dataset using either min-max or standard normalization.\n",
    "        Can be used for separate testing data normalization or for normalization of the whole dataset with other ranges.\n",
    "        Returns the normalized dataset.\n",
    "    \"\"\"\n",
    "    dataset_cpy = copy.deepcopy(dataset)\n",
    "    \n",
    "    if testing_data_norm is False:\n",
    "        if scaler is None:\n",
    "            if normalization_type == 'min-max':   \n",
    "                scaler = MinMaxScaler()\n",
    "            elif normalization_type == 'standard':\n",
    "                scaler = StandardScaler()\n",
    "        \n",
    "        # Normalize the dataset using the ranges given in normalization_ranges (min and max)        \n",
    "        # Used for separate testing data normalization or for normalization of the whole dataset with other ranges\n",
    "        \n",
    "        if normalization_ranges is not None:\n",
    "            X_min = normalization_ranges[\"min\"]\n",
    "            X_max = normalization_ranges[\"max\"]\n",
    "            dataset_cpy = [(arr - X_min) / (X_max - X_min) for arr in dataset_cpy]\n",
    "            \n",
    "        else:\n",
    "            dataset_flat = pd.concat(dataset_cpy, ignore_index=True)\n",
    "            # dataset_flat = np.vstack(dataset_cpy)\n",
    "            scaler.fit(dataset_flat)\n",
    "            \n",
    "            columns = dataset_cpy[0].columns\n",
    "            \n",
    "            for i in range(len(dataset_cpy)):\n",
    "                norm_dataset = scaler.transform(dataset_cpy[i])\n",
    "                norm_dataset = pd.DataFrame(norm_dataset, columns = columns)\n",
    "                dataset_cpy[i] = norm_dataset\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        if normalization_ranges is not None:\n",
    "            X_min = normalization_ranges[\"min\"]\n",
    "            X_max = normalization_ranges[\"max\"]\n",
    "            dataset_cpy = [(arr - X_min) / (X_max - X_min) for arr in dataset_cpy]\n",
    "            \n",
    "        else:\n",
    "            columns = dataset_cpy[0].columns\n",
    "        \n",
    "            for i in range(len(dataset_cpy)):\n",
    "                norm_dataset = scaler.transform(dataset_cpy[i])\n",
    "                norm_dataset = pd.DataFrame(norm_dataset, columns = columns)\n",
    "                dataset_cpy[i] = norm_dataset\n",
    "            \n",
    "    return scaler, dataset_cpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7624d4",
   "metadata": {},
   "source": [
    "##### **Denormalize Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac93781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_data(dataset, scaler = None, normalization_ranges = None):\n",
    "    \"\"\"\n",
    "        Function to denormalize the dataset using the scaler used to normalize the dataset.\n",
    "        Manual denormalization can be used for separate testing data denormalization or for denormalization of the whole dataset.\n",
    "    \"\"\"\n",
    "    dataset_cpy = copy.deepcopy(dataset)\n",
    "    \n",
    "    #######\n",
    "    if scaler is None and normalization_ranges is not None:\n",
    "        X_min = normalization_ranges[\"min\"]\n",
    "        X_max = normalization_ranges[\"max\"]\n",
    "        \n",
    "        dataset_cpy = [arr * (X_max - X_min) + X_min for arr in dataset]\n",
    "            \n",
    "    if scaler is not None:\n",
    "        for item in range(len(dataset)):\n",
    "            dataset_cpy[item] = scaler.inverse_transform(dataset_cpy[item])\n",
    "       \n",
    "    return dataset_cpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f224be7d",
   "metadata": {},
   "source": [
    "##### **Data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b38a12b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_reshape(X, Y, \n",
    "                seq_len,\n",
    "                num_feats, \n",
    "                num_outputs,\n",
    "                batch_size):\n",
    "    \"\"\"\n",
    "        Function to split the data into training and testing sets and reshape the data into the required shape for the LSTM model\n",
    "        Returns a dictionary with the following:\n",
    "            X_train: Training data for the input features\n",
    "            X_test: Testing data for the input features\n",
    "            Y_train: Training data for the output features\n",
    "            Y_test: Testing data for the output features    \n",
    "    \"\"\"\n",
    "    \n",
    "    valid_rows = X.shape[0] // seq_len * seq_len\n",
    "\n",
    "    if len(Y.shape) == 1:\n",
    "        X = X[:valid_rows]\n",
    "        Y = Y[:valid_rows]\n",
    "    else:\n",
    "        X = X[:valid_rows, :]\n",
    "        Y = Y[:valid_rows, :]\n",
    "\n",
    "    num_sequences = X.shape[0] // seq_len\n",
    "       \n",
    "    X = X.reshape(num_sequences, seq_len, num_feats)\n",
    "    Y = Y.reshape(num_sequences, seq_len, num_outputs)\n",
    "              \n",
    "    X_train = X[0: X.shape[0] - (X.shape[0] % batch_size)]\n",
    "    Y_train = Y[0: Y.shape[0] - (Y.shape[0] % batch_size)]\n",
    "       \n",
    "    data = {\"X_train\": X_train, \"Y_train\": Y_train}\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad03fae",
   "metadata": {},
   "source": [
    "##### **Train Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b2ba952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_preparation(X, Y,\n",
    "                            num_of_traj, \n",
    "                            BATCH_SIZE,\n",
    "                            TESTING_SIZE,\n",
    "                            SEQ_LEN,\n",
    "                            NUM_FEATS,\n",
    "                            NUM_OUTPUTS,\n",
    "                            ):\n",
    "    \"\"\"\n",
    "        Train data preparation\n",
    "        Return a numpy array of all trajectories, where each trajectory is padded with zeroes to a multiple of the SL.\n",
    "        After reshaping, each trajectory is a single numpy array of size (NUMBER OF SEQUENCES, SEQ_LEN, NUM_FEATS)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to NP Array and get the sequence lengths\n",
    "    training_size = int(num_of_traj * (1 - TESTING_SIZE))\n",
    "    train_traj_seq_lengths = [0.0] * training_size\n",
    "\n",
    "    X_concatenated, Y_concatenated = [], []\n",
    "\n",
    "    for i in range(training_size):\n",
    "        X[i] = np.array(X[i])\n",
    "        Y[i] = np.array(Y[i])\n",
    "\n",
    "        # For data reshaping later on\n",
    "        reminder = X[i].shape[0] % SEQ_LEN\n",
    "        \n",
    "        # Trim trajectories to seq_len and create a single numpy array with all trajectories\n",
    "        if (X[i].shape[0] >= SEQ_LEN):\n",
    "            X[i] = X[i][0 : (X[i].shape[0] - reminder), :]\n",
    "            Y[i] = Y[i][0 : (Y[i].shape[0] - reminder), :]\n",
    "\n",
    "            X_concatenated.extend(X[i])\n",
    "            Y_concatenated.extend(Y[i])\n",
    "        \n",
    "            train_traj_seq_lengths[i] = X[i].shape[0]\n",
    "            \n",
    "    X_new, Y_new = np.array(X_concatenated), np.array(Y_concatenated)\n",
    "\n",
    "    lstm_data = train_reshape(X_new, Y_new, SEQ_LEN, NUM_FEATS, NUM_OUTPUTS, BATCH_SIZE)\n",
    "\n",
    "    X_train = lstm_data[\"X_train\"]\n",
    "    Y_train = lstm_data[\"Y_train\"]\n",
    "    \n",
    "    return X_train, Y_train, training_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc76910",
   "metadata": {},
   "source": [
    "##### **Test Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3960f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_preparation(TRAINING_TESTING_SAME_FILE, \n",
    "                          num_of_traj,\n",
    "                          training_size,\n",
    "                          SEQ_LEN,\n",
    "                          NUM_FEATS,\n",
    "                          TESTING_FILE,\n",
    "                          data,\n",
    "                          X = None, Y = None,\n",
    "                          ):\n",
    "    \n",
    "    \"\"\"\n",
    "        Test data preparation\n",
    "        Returns a list of numpy arrays, where each array is a single trajectory.\n",
    "    \"\"\"\n",
    "\n",
    "    if TRAINING_TESTING_SAME_FILE:\n",
    "        X_test = [0.0] * (num_of_traj - training_size)\n",
    "        Y_test = [0.0] * (num_of_traj - training_size)\n",
    "\n",
    "        test_traj_seq_lengths = [0.0] * (num_of_traj - training_size + 1) \n",
    "\n",
    "        idx = 0\n",
    "        for i in range(training_size, num_of_traj):\n",
    "            X[i] = np.array(X[i])\n",
    "            Y[i] = np.array(Y[i])\n",
    "            \n",
    "            test_traj_seq_lengths[idx] = X[i].shape[0]\n",
    "            \n",
    "            # For data reshaping later on\n",
    "            seq_multiplier = X[i].shape[0] // SEQ_LEN\n",
    "            padding_size = (seq_multiplier + 1) * SEQ_LEN - X[i].shape[0]\n",
    "            \n",
    "            padding = np.zeros([ padding_size, NUM_FEATS ])\n",
    "            \n",
    "            X_test[idx] = np.vstack((X[i], padding))\n",
    "            Y_test[idx] = Y[i]\n",
    "            \n",
    "            idx += 1\n",
    "    else:\n",
    "        # In case the testing data is obtained from a different file:\n",
    "        data_test = load_data_from_pickle(TESTING_FILE)\n",
    "        \n",
    "        X_test = [0.0] * len(data_test)\n",
    "        Y_test = [0.0] * len(data_test)\n",
    "        \n",
    "        # Get trajectories min and max values\n",
    "        num_of_traj_test = len(data_test)\n",
    "\n",
    "        test_traj_seq_lengths = [0.0] * num_of_traj_test\n",
    "        \n",
    "        data_test = [data_test[i][COLUMNS] for i in range(num_of_traj_test)]\n",
    "\n",
    "        scaler, data_test = normalize_trajectory_data(dataset = data_test, normalization_type = 'min-max', testing_data_norm=True, scaler=scaler)\n",
    "\n",
    "        X_t, Y_t = [0.0] * num_of_traj_test, [0.0] * num_of_traj_test\n",
    "\n",
    "        for i in range(num_of_traj_test):\n",
    "            # X is composed of the trajectory data starting from the first point to the second last point\n",
    "            X_t[i] =  data[i][COLUMNS].iloc[0:-1] \n",
    "            X_t[i].columns = COLUMNS\n",
    "\n",
    "            # Y is composed of the trajectory data starting from the second point to the last point\n",
    "            Y_t[i] =  data[i][COLUMNS].iloc[1:] \n",
    "            Y_t[i].columns = COLUMNS\n",
    "\n",
    "        for i in range(num_of_traj_test):\n",
    "            X_t[i] = np.array(X_t[i])\n",
    "            Y_t[i] = np.array(Y_t[i])\n",
    "\n",
    "            test_traj_seq_lengths[i] = X[i].shape[0]\n",
    "            \n",
    "            # For data reshaping later on\n",
    "            seq_multiplier = X_t[i].shape[0] // SEQ_LEN\n",
    "            padding_size = (seq_multiplier + 1) * SEQ_LEN - X_t[i].shape[0]\n",
    "            \n",
    "            padding = np.zeros([ padding_size, NUM_FEATS ])\n",
    "            \n",
    "            X_test[i] = np.vstack((X_t[i], padding))\n",
    "            Y_test[i] = Y_t[i]\n",
    "            \n",
    "    return X_test, Y_test, test_traj_seq_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64acabd9",
   "metadata": {},
   "source": [
    "##### **Distance and Performance Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79af3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "        Compute great-circle (Haversine) distance between two lat/lon points in km.\n",
    "        Returns the distance in km.\n",
    "    \"\"\"\n",
    "\n",
    "    # Do this check if one argument is NaN\n",
    "    if pd.isna(lat1) or pd.isna(lon1) or pd.isna(lat2) or pd.isna(lon2):\n",
    "        return 0 # \n",
    "        \n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    return haversine_distances([[lat1, lon1], [lat2, lon2]])[0, 1] * 6371  #Earth radius in km\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f73fb001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance_tdrive(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "        Compute great-circle (Haversine) distance between two lat/lon points in km.\n",
    "        Returns the distance in km.\n",
    "    \"\"\"\n",
    "\n",
    "    # Do this check if one argument is NaN\n",
    "    if pd.isna(lat1) or pd.isna(lon1) or pd.isna(lat2) or pd.isna(lon2):\n",
    "        return np.nan # \n",
    "        \n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    return haversine_distances([[lat1, lon1], [lat2, lon2]])[0, 1] * 6371008.7714  #Earth radius in km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b65aa3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prediction_metrics(Y_test, Y_pred):\n",
    "    \"\"\"\n",
    "        Compute prediction metrics for the model\n",
    "        Returns a dictionary with the following metrics:\n",
    "        - MSE: Mean Squared Error\n",
    "        - KLD: Symetric Kullback-Leibler Divergence (Jeffreys divergence)\n",
    "        - ED: Energy Distance\n",
    "        - WD: Wasserstein Distance\n",
    "    \"\"\"\n",
    "    \n",
    "    # MSE, KLD, ED, WD, HAVERSINE (HS)\n",
    "    mse = mean_squared_error(Y_test, Y_pred)\n",
    "    # kld = keras.losses.KLDivergence(Y_test, Y_pred)\n",
    "    kld = 0\n",
    "    ed = float(energy_distance(Y_test, Y_pred))\n",
    "    wd = float(wasserstein_distance(Y_test, Y_pred))\n",
    "    \n",
    "    results = {\"MSE\" : mse, \"KLD\" : kld, \"ED\" : ed, \"WD\" : wd}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dea302ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_trajectory_metrics(Y_test, Y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "        Compute prediction metrics for the model\n",
    "        Returns a dictionary with the following metrics:\n",
    "        - IE: Individual Error\n",
    "        - ISE: Individual Squared Error\n",
    "        - MSE: Mean Squared Error\n",
    "        - ED: Energy Distance, averaged per features\n",
    "    \"\"\"\n",
    "    \n",
    "    errors = [0.0] * len(Y_test)\n",
    "    squared_errors = [0.0] * len(Y_test)\n",
    "    mses = [0.0] * len(Y_test)\n",
    "    eds = [0.0] * len(Y_test)\n",
    "    \n",
    "    for i in range(len(Y_test)):\n",
    "        \n",
    "        err = Y_test[i] - Y_pred[i]\n",
    "        squared_errors[i] = err**2\n",
    "        errors[i] = err\n",
    "        mses[i] = np.mean(err**2)\n",
    "        \n",
    "        eds1= float(energy_distance(Y_test[i][:,0], Y_pred[i][:,0]))\n",
    "        eds2 = float(energy_distance(Y_test[i][:,1], Y_pred[i][:,1]))\n",
    "        eds[i] = np.mean([eds1, eds2])\n",
    "        \n",
    "    results = {\"IE\" : errors, \"ISE\" : squared_errors, \"MSE\" : mses, \"ED\" : eds}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c625440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_point_to_point_haversine_distances(traj1, traj2):\n",
    "    \"\"\"\n",
    "    Compute the haversine point-to-point distance in meters between two trajectories.\n",
    "    \n",
    "    Parameters:\n",
    "        traj1 (array-like): First trajectory as a list or array of [latitude, longitude] pairs.\n",
    "        traj2 (array-like): Second trajectory as a list or array of [latitude, longitude] pairs.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of distances in meters between corresponding points in the two trajectories.\n",
    "    \"\"\"\n",
    "    if len(traj1) != len(traj2):\n",
    "        raise ValueError(\"Trajectories must have the same number of points.\")\n",
    "    \n",
    "    distances = []\n",
    "    for (lat1, lon1), (lat2, lon2) in zip(traj1, traj2):\n",
    "        # Convert degrees to radians\n",
    "        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "        # Compute haversine distance in kilometers and convert to meters\n",
    "        distance = haversine_distances([[lat1, lon1], [lat2, lon2]])[0, 1] * 6371000  # Earth radius in meters\n",
    "        distances.append(distance)\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2bc673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_loss(y_true, y_pred):\n",
    "    R = 6371.0  # Earth radius in km\n",
    "    DEG2RAD = math.pi / 180.0\n",
    "\n",
    "    lat1, lon1 = tf.unstack(y_true, axis=-1)\n",
    "    lat2, lon2 = tf.unstack(y_pred, axis=-1)\n",
    "\n",
    "    lat1 = lat1 * DEG2RAD\n",
    "    lon1 = lon1 * DEG2RAD\n",
    "    lat2 = lat2 * DEG2RAD\n",
    "    lon2 = lon2 * DEG2RAD\n",
    "\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    a = tf.sin(dlat / 2.0)**2 + tf.cos(lat1) * tf.cos(lat2) * tf.sin(dlon / 2.0)**2\n",
    "    c = 2.0 * tf.atan2(tf.sqrt(a), tf.sqrt(1.0 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    return tf.reduce_mean(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a469b2f0",
   "metadata": {},
   "source": [
    "##### **Trajectory Data Plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca534336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_act_pred_traj(predicted, \n",
    "                       actual, \n",
    "                       seq_len, \n",
    "                       scatter = False, \n",
    "                       trim_trajectory = False, \n",
    "                       k=1, \n",
    "                       show = True,\n",
    "                       x_range = None,\n",
    "                       y_range = None):\n",
    "    \"\"\"\n",
    "        Plots the actual and predicted trajectories.\n",
    "        Set scatter to True to plot the trajectories as scatter plots.\n",
    "        Set trim_trajectory to True to plot the trajectories with the same length.\n",
    "        Set show to False to not show the plot.\n",
    "        Saves the plot to a file.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not trim_trajectory:\n",
    "        LEN = seq_len\n",
    "        \n",
    "    fig_lons_max = max(actual.lons.max(), predicted.lons.max())\n",
    "    fig_lons_min = min(actual.lons.min(), predicted.lons.min())\n",
    "\n",
    "    fig_lats_max = max(actual.lats.max(), predicted.lats.max())\n",
    "    fig_lats_min = min(actual.lats.min(), predicted.lats.min())\n",
    "    \n",
    "    plt.figure()\n",
    "    if show == True:\n",
    "        plt.show()\n",
    "        \n",
    "    plt.xlim([fig_lons_min, fig_lons_max])\n",
    "    plt.ylim([fig_lats_min, fig_lats_max])\n",
    "    \n",
    "    for act, pred in zip(actual.groupby(\"id\"), predicted.groupby(\"id\")):\n",
    "                   \n",
    "        act_x, act_y = list(act[1].lons), list(act[1].lats) \n",
    "        \n",
    "        if trim_trajectory:\n",
    "            LEN = list(act[1].length)[0]\n",
    "        \n",
    "        if not scatter:\n",
    "            plt.plot(act_x[0:LEN], act_y[0:LEN], marker=\"None\", linestyle=\"-\", linewidth=0.35, color=\"black\")\n",
    "        else:\n",
    "            plt.scatter(act_x[0:LEN], act_y[0:LEN],  linewidth=0.35, color=\"black\")\n",
    "        \n",
    "        pred_x, pred_y = list(pred[1].lons), list(pred[1].lats)\n",
    "        \n",
    "        if not scatter:\n",
    "            plt.plot(pred_x[0:LEN], pred_y[0:LEN], marker=\"None\", linestyle=\"-\", linewidth=0.35, color=\"red\")\n",
    "        else:\n",
    "            plt.scatter(pred_x[0:LEN], pred_y[0:LEN],  linewidth=0.35, color=\"red\", alpha=0.5)\n",
    "        \n",
    "    plt.grid(True)\n",
    "    plt.title(\"Actual vs. Predicted Trajectory for k = \" + str(k))    \n",
    "    plt.legend([\"Actual\", \"Predicted\"])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"plots/Predictions\" + str(k) + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ece8ee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_act_pred_traj_one_by_one(predicted, \n",
    "                                    actual, \n",
    "                                    seq_len, \n",
    "                                    scatter = True, \n",
    "                                    trim_trajectory = False, \n",
    "                                    k=1, \n",
    "                                    show = True, \n",
    "                                    num_of_traj_to_plot = 20, \n",
    "                                    start_traj = 0,\n",
    "                                    end_traj = 0,\n",
    "                                    x_range = None,\n",
    "                                    y_range = None,\n",
    "                                    range = None,\n",
    "                                    path = None):\n",
    "    \"\"\"\n",
    "        Plots the actual and predicted trajectories.\n",
    "        Set scatter to True to plot the trajectories as scatter plots.\n",
    "        Set trim_trajectory to True to plot the trajectories with the same length.\n",
    "        Set show to False to not show the plot.\n",
    "        Saves the plot to a file.\n",
    "    \"\"\"\n",
    "           \n",
    "    # fig_lons_max = max(actual.lons.max(), predicted.lons.max())\n",
    "    # fig_lons_min = min(actual.lons.min(), predicted.lons.min())\n",
    "\n",
    "    # fig_lats_max = max(actual.lats.max(), predicted.lats.max())\n",
    "    # fig_lats_min = min(actual.lats.min(), predicted.lats.min())\n",
    "    errors_x = []\n",
    "    errors_y = []\n",
    "    \n",
    "    plt.figure()\n",
    "    if show == True:\n",
    "        plt.show()\n",
    "    \n",
    "    if x_range is not None:\n",
    "        plt.xlim(x_range)\n",
    "        \n",
    "    if y_range is not None:\n",
    "        plt.ylim(y_range)\n",
    "    \n",
    "    # plt.xlim([fig_lons_min, fig_lons_max])\n",
    "    # plt.ylim([fig_lats_min, fig_lats_max])\n",
    "    \n",
    "    index = 0\n",
    "    size = 50\n",
    "    for act, pred in zip(actual, predicted):\n",
    "        \n",
    "        if (end_traj != -1 and index >= start_traj and index <= end_traj) or (range is not None and index in range):\n",
    "                \n",
    "            act_x, act_y = act[:, 0], act[:, 1] \n",
    "            \n",
    "            # Plot the trajectory\n",
    "            if not scatter:\n",
    "                plt.plot(act_x, act_y, marker=\"None\", linestyle=\"-\", linewidth=0.35, color=\"black\")\n",
    "            else:\n",
    "                plt.scatter(act_x, act_y,  s = 50, linewidth=0.35, color=\"black\")\n",
    "            \n",
    "            # Plot the starting and ending point of the trajectory\n",
    "            # Dont add it to the legend\n",
    "            \n",
    "            plt.scatter(act_x[0], act_y[0],  s = size, linewidth=0.35, color=\"black\")\n",
    "            plt.scatter(act_x[-1], act_y[-1],  s = size, linewidth=0.35, color=\"black\", alpha=0.5)\n",
    "            \n",
    "            pred_x, pred_y = pred[:, 0], pred[:, 1]\n",
    "            \n",
    "            if not scatter:\n",
    "                plt.plot(pred_x, pred_y, marker=\"None\", linestyle=\"-\", linewidth=0.35, color=\"red\")\n",
    "            else:\n",
    "                plt.scatter(pred_x, pred_y, s = 50, linewidth=0.35, color=\"red\", alpha=0.5)\n",
    "            \n",
    "            # Plot the starting and ending point of the trajectory\n",
    "            plt.scatter(pred_x[0], pred_y[0],  s = size, linewidth=0.35, color=\"red\")\n",
    "            plt.scatter(pred_x[-1], pred_y[-1],  s = size, linewidth=0.35, color=\"red\", alpha=0.5)\n",
    "            \n",
    "            errors_x.append(act_x - pred_x)\n",
    "            errors_y.append(act_y - pred_y)\n",
    "            \n",
    "        index += 1\n",
    "        \n",
    "    plt.grid(True)\n",
    "    plt.title(\"Actual vs. Predicted Trajectory\")    \n",
    "    plt.legend([\"Actual\", \"Start point\", \"End point\", \"Predicted\" ])\n",
    "    # plt.show()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if path is not None:\n",
    "        plt.savefig(path + \"Predictions\" + str(k) + \".pdf\")\n",
    "    else:\n",
    "        plt.savefig(\"plots/Predictions\" + str(k) + \".pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6048e6",
   "metadata": {},
   "source": [
    "##### **Create LSTM and Recurrent Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daea19ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LSTM_model(LSTM_cells, \n",
    "                      seq_len, \n",
    "                      num_feat,\n",
    "                      batch_size,\n",
    "                      stateful,\n",
    "                      return_seq,\n",
    "                      num_outputs,\n",
    "                      LR,\n",
    "                      SEED,\n",
    "                      ragged = False):\n",
    "    \"\"\"\n",
    "        Create an LSTM model with the specified parameters\n",
    "        Returns the untrained model\n",
    "    \"\"\"\n",
    "    \n",
    "    keras.utils.set_random_seed(SEED)\n",
    "\n",
    "    # In newer versions of Keras, for stateful LSTM, you need to specify the batch_input_shape as the first layer (input layer)\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Ragged tensor for variable length sequences\n",
    "    if ragged is False:\n",
    "        model.add(keras.layers.InputLayer(batch_input_shape=(batch_size, seq_len, num_feat)))\n",
    "        model.add(keras.layers.LSTM(LSTM_cells, return_sequences = return_seq, stateful = stateful))\n",
    "    else:\n",
    "        model.add(keras.layers.InputLayer(shape=[None, num_feat], batch_size = batch_size, dtype=tf.float32, ragged = True))\n",
    "        model.add(keras.layers.LSTM(LSTM_cells, return_sequences = return_seq, stateful = False))\n",
    "        \n",
    "    model.add(keras.layers.Dense(num_outputs))\n",
    "    \n",
    "    \n",
    "    # https://keras.io/api/optimizers/learning_rate_schedules/exponential_decay/\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate = LR,\n",
    "        decay_steps = 50,\n",
    "        decay_rate = 0.99) \n",
    "    \n",
    "    model.compile(optimizer = \"adam\", \n",
    "                  loss = \"mse\", \n",
    "                  #loss = haversine_loss,\n",
    "                  #metrics = [\"mse\", \"mae\", \"mape\", \"kl_divergence\"])\n",
    "                  metrics = [\"mse\"])\n",
    "    \n",
    "    # https://keras.io/api/optimizers/\n",
    "    model.optimizer.lr=lr_schedule\n",
    "    # mdl.optimizer.momentum = 0.99\n",
    "    # mdl.optimizer.use_ema = True\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ac7efa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_RNN_model(RNN_cells, \n",
    "                      seq_len, \n",
    "                      num_feat,\n",
    "                      batch_size,\n",
    "                      stateful,\n",
    "                      return_seq,\n",
    "                      num_outputs,\n",
    "                      LR,\n",
    "                      SEED,\n",
    "                      ragged = False):\n",
    "    \"\"\"\n",
    "        Create an LSTM model with the specified parameters\n",
    "        Returns the untrained model\n",
    "    \"\"\"\n",
    "    \n",
    "    keras.utils.set_random_seed(SEED)\n",
    "\n",
    "    # In newer versions of Keras, for stateful LSTM, you need to specify the batch_input_shape as the first layer (input layer)\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Ragged tensor for variable length sequences\n",
    "    if ragged is False:\n",
    "        model.add(keras.layers.InputLayer(batch_input_shape=(batch_size, seq_len, num_feat)))\n",
    "        model.add(keras.layers.SimpleRNN(RNN_cells, return_sequences = return_seq, stateful = stateful))\n",
    "    else:\n",
    "        model.add(keras.layers.InputLayer(shape=[None, num_feat], batch_size = batch_size, dtype=tf.float32, ragged = True))\n",
    "        model.add(keras.layers.SimpleRNN(RNN_cells, return_sequences = return_seq, stateful = False))\n",
    "        \n",
    "    model.add(keras.layers.Dense(num_outputs))\n",
    "    \n",
    "    \n",
    "    # https://keras.io/api/optimizers/learning_rate_schedules/exponential_decay/\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate = LR,\n",
    "        decay_steps = 40,\n",
    "        decay_rate = 0.96) \n",
    "    \n",
    "    model.compile(optimizer = \"adam\", \n",
    "                  loss = \"mse\", \n",
    "                  metrics = [\"mse\", \"mae\", \"mape\", \"kl_divergence\"])\n",
    "    \n",
    "    # https://keras.io/api/optimizers/\n",
    "    model.optimizer.lr=lr_schedule\n",
    "    # mdl.optimizer.momentum = 0.99\n",
    "    # mdl.optimizer.use_ema = True\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b5542ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_GRU_model(GRU_cells, \n",
    "                      seq_len, \n",
    "                      num_feat,\n",
    "                      batch_size,\n",
    "                      stateful,\n",
    "                      return_seq,\n",
    "                      num_outputs,\n",
    "                      LR,\n",
    "                      SEED,\n",
    "                      ragged = False,\n",
    "                      layers = 1,\n",
    "                      GRU_cells_2 = 0,\n",
    "                      GRU_cells_3 = 0):\n",
    "    \"\"\"\n",
    "        Create an GRU model with the specified parameters\n",
    "        Returns the untrained model\n",
    "    \"\"\"\n",
    "    \n",
    "    keras.utils.set_random_seed(SEED)\n",
    "\n",
    "    # In newer versions of Keras, for stateful LSTM, you need to specify the batch_input_shape as the first layer (input layer)\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Ragged tensor for variable length sequences\n",
    "    if ragged is False:\n",
    "        model.add(keras.layers.InputLayer(batch_input_shape=(batch_size, seq_len, num_feat)))\n",
    "        model.add(keras.layers.GRU(GRU_cells, return_sequences = return_seq, stateful = stateful))\n",
    "        if GRU_cells_2 > 0:\n",
    "            model.add(keras.layers.GRU(GRU_cells_2, return_sequences = return_seq, stateful = stateful))\n",
    "        if GRU_cells_3 > 0:\n",
    "            model.add(keras.layers.GRU(GRU_cells_3, return_sequences = return_seq, stateful = stateful))\n",
    "    else:\n",
    "        model.add(keras.layers.InputLayer(shape=[None, num_feat], batch_size = batch_size, dtype=tf.float32, ragged = True))\n",
    "        model.add(keras.layers.GRU(GRU_cells, return_sequences = return_seq, stateful = False))\n",
    "        if GRU_cells_2 > 0:\n",
    "            model.add(keras.layers.GRU(GRU_cells_2, return_sequences = return_seq, stateful = False))\n",
    "        if GRU_cells_3 > 0:\n",
    "            model.add(keras.layers.GRU(GRU_cells_3, return_sequences = return_seq, stateful = False))\n",
    "        \n",
    "    model.add(keras.layers.Dense(num_outputs))\n",
    "    \n",
    "    \n",
    "    # https://keras.io/api/optimizers/learning_rate_schedules/exponential_decay/\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate = LR,\n",
    "        decay_steps = 40,\n",
    "        decay_rate = 0.96) \n",
    "    \n",
    "    # early stopping\n",
    "    model.compile(optimizer = \"adam\", \n",
    "                  loss = \"mse\", \n",
    "                  metrics = [\"mse\", \"mae\", \"mape\", \"kl_divergence\"]\n",
    "                  )\n",
    "    \n",
    "    # https://keras.io/api/optimizers/\n",
    "    model.optimizer.lr=lr_schedule\n",
    "    # mdl.optimizer.momentum = 0.99\n",
    "    # mdl.optimizer.use_ema = True\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb322a66",
   "metadata": {},
   "source": [
    "##### **Train LSTM Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9e6fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras training loop\n",
    "def train_model(model, \n",
    "                X_train, Y_train, \n",
    "                epochs,\n",
    "                batch_size):\n",
    "    \"\"\"\n",
    "        Train the LSTM model with the default keras method\n",
    "        Returns the training history and the trained model\n",
    "    \"\"\"\n",
    "    history = model.fit(X_train, \n",
    "                        Y_train, \n",
    "                        batch_size = batch_size, \n",
    "                        epochs = epochs, \n",
    "                        verbose = 0, \n",
    "                        shuffle = False)\n",
    "                        # callbacks =  [keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)])\n",
    "        \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a77df1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual training loop\n",
    "def train_model_manual_loop(model, \n",
    "                            epochs,\n",
    "                            LR,\n",
    "                            batch_size,\n",
    "                            X_train = None,\n",
    "                            Y_train = None,\n",
    "                            reset_states = True):\n",
    "    \"\"\"\n",
    "        Manual training loop for the LSTM model\n",
    "        Works with the model created with the create_LSTM_model function\n",
    "        Works for any batch size\n",
    "        Returns the training history and the trained model\n",
    "    \"\"\"\n",
    "    \n",
    "    loss_fn = keras.losses.MeanSquaredError()\n",
    "    \n",
    "    optimizer = model.optimizer\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        for step in range(0, len(X_train), batch_size):\n",
    "\n",
    "            x_batch = X_train[step : step + batch_size]  \n",
    "            y_batch = Y_train[step : step + batch_size]  \n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions = model(x_batch, training=True)\n",
    "                loss = loss_fn(y_batch, predictions)\n",
    "\n",
    "            # Get gradients\n",
    "            trainable_vars = model.trainable_variables\n",
    "            gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "            # Apply gradients to update model weights\n",
    "            optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "            \n",
    "            # Reset states after batch\n",
    "            if reset_states:\n",
    "                model.reset_states()\n",
    "            \n",
    "    return model.history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a90db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual training loop with sequence resets\n",
    "def train_model_train_on_batch(model, \n",
    "                                X, Y, \n",
    "                                batch_size , \n",
    "                                epochs):\n",
    "    \"\"\"\n",
    "        Manual training loop with sequence resets and train on batch\n",
    "        Works for stateful and stateless models\n",
    "        Works for any batch size\n",
    "        Returns the trained model\n",
    "    \"\"\"\n",
    "    # Manual training loop with sequence resets used with train_on_baatch\n",
    "    for epoch in range(epochs):\n",
    "        for start in range(0, len(X), batch_size):\n",
    "            model.train_on_batch(X[start : start + batch_size], Y[start : start + batch_size])\n",
    "            model.reset_states()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4c9ab9",
   "metadata": {},
   "source": [
    "##### **Test LSTM Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbe47d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, \n",
    "               X_test, \n",
    "               Y_test, \n",
    "               batch_size):\n",
    "    \"\"\"\n",
    "        Works for both stateful and non-stateful models\n",
    "        Works for any batch size\n",
    "        Returns the predictions of the model on the test data\n",
    "    \"\"\"\n",
    "    \n",
    "    Y_pred = model.predict(X_test, batch_size = batch_size, verbose = 0).reshape(-1, 1).flatten()\n",
    "    Y_test = Y_test.reshape(-1, 1).flatten()\n",
    "    \n",
    "    return Y_test, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8140f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_per_trajectory(mdl, \n",
    "                            X_t, \n",
    "                            test_traj_seq_lengths,\n",
    "                            SEQ_LENGTH,\n",
    "                            NUM_FEATS\n",
    "                            ):\n",
    "    \"\"\"\n",
    "        Works for both stateful and non-stateful models\n",
    "        Works for any batch size\n",
    "        Returns the predictions of the model on the test data\n",
    "    \"\"\"\n",
    "    mdl.layers[0].reset_states()\n",
    "    \n",
    "    Y_preds = [0.0] * len(X_t)\n",
    "\n",
    "    for i in range(len(X_t)):\n",
    "        X_t[i] = X_t[i].reshape(-1, SEQ_LENGTH, NUM_FEATS)\n",
    "    \n",
    "    for i in range(len(X_t)):\n",
    "        \n",
    "        y_pred = mdl.predict(X_t[i], batch_size = 1, verbose = 0).reshape(-1, NUM_FEATS)\n",
    "        y_pred = y_pred[0:test_traj_seq_lengths[i], :]\n",
    "        Y_preds[i] = y_pred\n",
    "        \n",
    "        mdl.layers[0].reset_states()\n",
    "        \n",
    "    return Y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b51f7e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_all_trajectories(model, \n",
    "                                X_test, \n",
    "                                Y_test, \n",
    "                                batch_size):\n",
    "    \"\"\"\n",
    "        Works for both stateful and non-stateful models\n",
    "        Works for any batch size\n",
    "        Returns the predictions of the model on the test data\n",
    "    \"\"\"\n",
    "    \n",
    "    Y_pred = model.predict(X_test, batch_size = batch_size).reshape(-1, 1).flatten()\n",
    "    Y_test = Y_test.reshape(-1, 1).flatten()\n",
    "   \n",
    "    return Y_test, Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162dbd96",
   "metadata": {},
   "source": [
    "## **Experiments**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e3b316",
   "metadata": {},
   "source": [
    "#### **Load Trajectory Data Once**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcb267bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trajectory data for faster execution\n",
    "data = load_data_from_pickle(DATASET[SELECTED_DATASET], TOTAL_TRAJS)\n",
    "\n",
    "# Get the data in the selected square\n",
    "data = get_data_in_square(data = data, square = DATA_SQUARE[SELECTED_DATASET])\n",
    "\n",
    "# Get trajectories min and max values\n",
    "mins, maxs =  get_min_max_from_data(data)\n",
    "\n",
    "# Get number of trajectories\n",
    "num_of_traj = len(data)\n",
    "\n",
    "# Normalize the data using the min and max values\n",
    "normalization_ranges = {\"min\": mins, \"max\": maxs}\n",
    "\n",
    "# Only keep the lat and lon columns for now\n",
    "data = [data[i][COLUMNS] for i in range(num_of_traj)]\n",
    "\n",
    "# Normalize the data using scaler or normalization ranges\n",
    "scaler, data = normalize_trajectory_data(dataset = data, normalization_type = 'min-max')\n",
    "\n",
    "# Create X and Y from the data\n",
    "X, Y =  create_X_Y_from_data(data, num_of_traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9126e11d",
   "metadata": {},
   "source": [
    "#### **Create Trajectory Data Training/Testing Splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf28b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data Preparation\n",
    "X_train, Y_train, training_size = train_data_preparation(X = copy.deepcopy(X) , Y= copy.deepcopy(Y),\n",
    "                                                        num_of_traj = num_of_traj,\n",
    "                                                        BATCH_SIZE = BATCH_SIZE,\n",
    "                                                        TESTING_SIZE = TESTING_SIZE,\n",
    "                                                        SEQ_LEN = SEQ_LEN,\n",
    "                                                        NUM_FEATS = NUM_FEATS,\n",
    "                                                        NUM_OUTPUTS = NUM_OUTPUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387458fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data Preparation\n",
    "X_test, Y_test, test_traj_seq_lengths = test_data_preparation(TRAINING_TESTING_SAME_FILE = TRAINING_TESTING_SAME_FILE,\n",
    "                                                                X = copy.deepcopy(X), Y = copy.deepcopy(Y),\n",
    "                                                                num_of_traj = num_of_traj,\n",
    "                                                                training_size = training_size,\n",
    "                                                                SEQ_LEN = SEQ_LEN,\n",
    "                                                                NUM_FEATS = NUM_FEATS,\n",
    "                                                                TESTING_FILE = None,\n",
    "                                                                data = data)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9865b35a",
   "metadata": {},
   "source": [
    "#### **Hyperparameter Optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b7fe08",
   "metadata": {},
   "source": [
    "##### **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00802a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_optimization(hyperparameters, NUM_FEATS, NUM_OUTPUTS):\n",
    "    best_model =  np.inf\n",
    "    best_hyperparameters = None\n",
    "\n",
    "    for batch_size in hyperparameters[\"batch_size\"]:\n",
    "        for SL in hyperparameters[\"seq_len\"]:\n",
    "            # Train Data Preparation\n",
    "            gc.collect()\n",
    "            keras.backend.clear_session()   \n",
    "            X_train, Y_train, training_size = train_data_preparation(X = copy.deepcopy(X) , Y= copy.deepcopy(Y),\n",
    "                                                                    num_of_traj = num_of_traj,\n",
    "                                                                    BATCH_SIZE = batch_size,\n",
    "                                                                    TESTING_SIZE = TESTING_SIZE,\n",
    "                                                                    SEQ_LEN = SL,\n",
    "                                                                    NUM_FEATS = NUM_FEATS,\n",
    "                                                                    NUM_OUTPUTS = NUM_OUTPUTS)\n",
    "            \n",
    "            X_test, Y_test, test_traj_seq_lengths = test_data_preparation(TRAINING_TESTING_SAME_FILE = TRAINING_TESTING_SAME_FILE,\n",
    "                                                X = copy.deepcopy(X), Y = copy.deepcopy(Y),\n",
    "                                                num_of_traj = num_of_traj,\n",
    "                                                training_size = training_size,\n",
    "                                                SEQ_LEN = SL,\n",
    "                                                NUM_FEATS = NUM_FEATS,\n",
    "                                                TESTING_FILE = None,\n",
    "                                                data = data)\n",
    "            \n",
    "            for LAYERS_REC in hyperparameters[\"LAYERS\"]:\n",
    "                #for cells in hyperparameters[\"cells\"]:\n",
    "                for cells in hyperparameters[\"cells\"]:\n",
    "                    for cells_l2 in hyperparameters[\"cells\"]:\n",
    "                        if LAYERS_REC == 1:\n",
    "                            break\n",
    "                        for cells_l3 in hyperparameters[\"cells\"]:\n",
    "                            if LAYERS_REC == 2:\n",
    "                                break\n",
    "                            for lr in hyperparameters[\"LR\"]:\n",
    "                                for epochs in hyperparameters[\"EPOCHS\"]:\n",
    "                                    \n",
    "                                    # Clear the model and reset \n",
    "                                    gc.collect()\n",
    "                                    keras.backend.clear_session()   \n",
    "                                    \n",
    "                                    print(f\"Training LSTM model with {LAYERS_REC} layers, {cells} LSTM cells, {cells_l2} LSTM cells 2, {cells_l3} LSTM cells 3,  {batch_size} batch size, LR = {lr}, epochs = {epochs}, seq_len = {SL}\")\n",
    "                                    \n",
    "                                    model = create_GRU_model(layers= LAYERS_REC,\n",
    "                                                            GRU_cells=cells,\n",
    "                                                            GRU_cells_2=cells_l2,\n",
    "                                                            GRU_cells_3=cells_l3,\n",
    "                                                            seq_len = SL,\n",
    "                                                            num_feat = NUM_FEATS,\n",
    "                                                            batch_size = batch_size,\n",
    "                                                            stateful = hyperparameters[\"stateful\"],\n",
    "                                                            return_seq = RETURN_SEQ,\n",
    "                                                            num_outputs = NUM_OUTPUTS,\n",
    "                                                            LR = lr,\n",
    "                                                            SEED = SEED,\n",
    "                                                            ragged = False)\n",
    "\n",
    "                                    history, model = train_model(model = model,\n",
    "                                                                X_train = X_train,  \n",
    "                                                                Y_train = Y_train,\n",
    "                                                                epochs = epochs,\n",
    "                                                                batch_size = batch_size   ) \n",
    "\n",
    "\n",
    "                                    model_sl1 = create_GRU_model(GRU_cells= cells,\n",
    "                                                            GRU_cells_2=cells_l2,\n",
    "                                                            GRU_cells_3=cells_l3,\n",
    "                                                            seq_len = SL,\n",
    "                                                            num_feat = NUM_FEATS,\n",
    "                                                            batch_size = 1,\n",
    "                                                            stateful = True,\n",
    "                                                            return_seq = RETURN_SEQ,\n",
    "                                                            num_outputs = NUM_OUTPUTS,\n",
    "                                                            LR = lr,\n",
    "                                                            SEED = SEED,\n",
    "                                                            ragged = False)\n",
    "\n",
    "                                    # Set weights and states\n",
    "                                    model_sl1.set_weights(model.get_weights())\n",
    "                                    \n",
    "                                    # Select best model based on testing loss\n",
    "                                    Y_pred = test_model_per_trajectory(mdl = model_sl1, \n",
    "                                                                        X_t = X_test,\n",
    "                                                                        test_traj_seq_lengths = test_traj_seq_lengths,\n",
    "                                                                        SEQ_LENGTH=SL,\n",
    "                                                                        NUM_FEATS=NUM_FEATS)\n",
    "\n",
    "                                    results = compute_trajectory_metrics(Y_test = Y_test, Y_pred = Y_pred)\n",
    "                                    \n",
    "                                    loss = np.mean(results[\"MSE\"])\n",
    "                                        \n",
    "                                    if  loss <= best_model:\n",
    "                                        best_hyperparameters = {\n",
    "                                            \"layers\": LAYERS_REC,\n",
    "                                            \"cells\": cells,\n",
    "                                            \"seq_len\": SL,\n",
    "                                            \"batch_size\": batch_size,\n",
    "                                            \"stateful\": hyperparameters[\"stateful\"],\n",
    "                                            \"LR\": lr,\n",
    "                                            \"EPOCHS\": epochs   \n",
    "                                        }\n",
    "                                        print(\"Best Hyperparameters: \", best_hyperparameters)\n",
    "                                        best_model = loss\n",
    "                                        best_mod = model\n",
    "                                        print(\"Best model found with loss: \", best_model)\n",
    "\n",
    "                        for lr in hyperparameters[\"LR\"]:\n",
    "                            for epochs in hyperparameters[\"EPOCHS\"]:\n",
    "                                \n",
    "                                # Clear the model and reset \n",
    "                                gc.collect()\n",
    "                                keras.backend.clear_session()   \n",
    "                                \n",
    "                                print(f\"Training LSTM model with {LAYERS_REC} layers, {cells} LSTM cells, {cells_l2} LSTM cells 2, {batch_size} batch size, LR = {lr}, epochs = {epochs}, seq_len = {SL}\")\n",
    "\n",
    "                                model = create_GRU_model(layers= LAYERS_REC,\n",
    "                                                        GRU_cells=cells,\n",
    "                                                        GRU_cells_2=cells_l2,\n",
    "                                                        seq_len = SL,\n",
    "                                                        num_feat = NUM_FEATS,\n",
    "                                                        batch_size = batch_size,\n",
    "                                                        stateful = hyperparameters[\"stateful\"],\n",
    "                                                        return_seq = RETURN_SEQ,\n",
    "                                                        num_outputs = NUM_OUTPUTS,\n",
    "                                                        LR = lr,\n",
    "                                                        SEED = SEED,\n",
    "                                                        ragged = False)\n",
    "\n",
    "                                history, model = train_model(model = model,\n",
    "                                                            X_train = X_train,  \n",
    "                                                            Y_train = Y_train,\n",
    "                                                            epochs = epochs,\n",
    "                                                            batch_size = batch_size   ) \n",
    "\n",
    "\n",
    "                                model_sl1 = create_GRU_model(layers= LAYERS_REC,\n",
    "                                                        GRU_cells=cells,\n",
    "                                                        GRU_cells_2=cells_l2,\n",
    "                                                        seq_len = SL,\n",
    "                                                        num_feat = NUM_FEATS,\n",
    "                                                        batch_size = 1,\n",
    "                                                        stateful = True,\n",
    "                                                        return_seq = RETURN_SEQ,\n",
    "                                                        num_outputs = NUM_OUTPUTS,\n",
    "                                                        LR = lr,\n",
    "                                                        SEED = SEED,\n",
    "                                                        ragged = False)\n",
    "\n",
    "                                # Set weights and states\n",
    "                                model_sl1.set_weights(model.get_weights())\n",
    "                                \n",
    "                                # Select best model based on testing loss\n",
    "                                Y_pred = test_model_per_trajectory(mdl = model_sl1, \n",
    "                                                                    X_t = X_test,\n",
    "                                                                    test_traj_seq_lengths = test_traj_seq_lengths,\n",
    "                                                                    SEQ_LENGTH=SL,\n",
    "                                                                    NUM_FEATS=NUM_FEATS)\n",
    "\n",
    "                                results = compute_trajectory_metrics(Y_test = Y_test, Y_pred = Y_pred)\n",
    "                                \n",
    "                                loss = np.mean(results[\"MSE\"])\n",
    "                                    \n",
    "                                if  loss <= best_model:\n",
    "                                    best_hyperparameters = {\n",
    "                                        \"layers\": LAYERS_REC,\n",
    "                                        \"cells\": cells,\n",
    "                                        \"seq_len\": SL,\n",
    "                                        \"batch_size\": batch_size,\n",
    "                                        \"stateful\": hyperparameters[\"stateful\"],\n",
    "                                        \"LR\": lr,\n",
    "                                        \"EPOCHS\": epochs   \n",
    "                                    }\n",
    "                                    print(\"Best Hyperparameters: \", best_hyperparameters)\n",
    "                                    best_model = loss\n",
    "                                    best_mod = model\n",
    "                                    print(\"Best model found with loss: \", best_model)\n",
    "\n",
    "                    for lr in hyperparameters[\"LR\"]:\n",
    "                        for epochs in hyperparameters[\"EPOCHS\"]:\n",
    "                            \n",
    "                            # Clear the model and reset \n",
    "                            gc.collect()\n",
    "                            keras.backend.clear_session()   \n",
    "                            \n",
    "                            print(f\"Training LSTM model with {LAYERS_REC} layers, {cells} LSTM cells,  {batch_size} batch size, LR = {lr}, epochs = {epochs}, seq_len = {SL}\")\n",
    "                            \n",
    "                            model = create_GRU_model(layers= LAYERS_REC,\n",
    "                                                    GRU_cells=cells,\n",
    "                                                    seq_len = SL,\n",
    "                                                    num_feat = NUM_FEATS,\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    stateful = hyperparameters[\"stateful\"],\n",
    "                                                    return_seq = RETURN_SEQ,\n",
    "                                                    num_outputs = NUM_OUTPUTS,\n",
    "                                                    LR = lr,\n",
    "                                                    SEED = SEED,\n",
    "                                                    ragged = False)\n",
    "\n",
    "                            history, model = train_model(model = model,\n",
    "                                                        X_train = X_train,  \n",
    "                                                        Y_train = Y_train,\n",
    "                                                        epochs = epochs,\n",
    "                                                        batch_size = batch_size)    \n",
    "\n",
    "\n",
    "                            model_sl1 = create_GRU_model(layers= LAYERS_REC,\n",
    "                                                        GRU_cells=cells,\n",
    "                                                        seq_len = SL,\n",
    "                                                        num_feat = NUM_FEATS,\n",
    "                                                        batch_size = 1,\n",
    "                                                        stateful = True,\n",
    "                                                        return_seq = RETURN_SEQ,\n",
    "                                                        num_outputs = NUM_OUTPUTS,\n",
    "                                                        LR = lr,\n",
    "                                                        SEED = SEED,\n",
    "                                                        ragged = False)\n",
    "\n",
    "                            # Set weights and states\n",
    "                            model_sl1.set_weights(model.get_weights())\n",
    "                            \n",
    "                            # Select best model based on testing loss\n",
    "                            Y_pred = test_model_per_trajectory(mdl = model_sl1, \n",
    "                                                                X_t = X_test,\n",
    "                                                                test_traj_seq_lengths = test_traj_seq_lengths,\n",
    "                                                                SEQ_LENGTH=SL,\n",
    "                                                                NUM_FEATS=NUM_FEATS)\n",
    "\n",
    "                            results = compute_trajectory_metrics(Y_test = Y_test, Y_pred = Y_pred)\n",
    "                            \n",
    "                            loss = np.mean(results[\"MSE\"])\n",
    "                                \n",
    "                            if  loss <= best_model:\n",
    "                                best_hyperparameters = {\n",
    "                                    \"layers\": LAYERS_REC,\n",
    "                                    \"cells\": cells,\n",
    "                                    \"seq_len\": SL,\n",
    "                                    \"batch_size\": batch_size,\n",
    "                                    \"stateful\": hyperparameters[\"stateful\"],\n",
    "                                    \"LR\": lr,\n",
    "                                    \"EPOCHS\": epochs   \n",
    "                                }\n",
    "                                print(\"Best Hyperparameters: \", best_hyperparameters)\n",
    "                                best_model = loss\n",
    "                                best_mod = model\n",
    "                                print(\"Best model found with loss: \", best_model)\n",
    "            \n",
    "    return best_mod, best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe928a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM model with 2 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Best Hyperparameters:  {'layers': 2, 'cells': 16, 'seq_len': 10, 'batch_size': 8, 'stateful': [True], 'LR': 0.001, 'EPOCHS': 25}\n",
      "Best model found with loss:  6.996309320902021e-05\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Best Hyperparameters:  {'layers': 2, 'cells': 16, 'seq_len': 10, 'batch_size': 8, 'stateful': [True], 'LR': 0.001, 'EPOCHS': 50}\n",
      "Best model found with loss:  6.741343996212008e-05\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Best Hyperparameters:  {'layers': 2, 'cells': 16, 'seq_len': 10, 'batch_size': 8, 'stateful': [True], 'LR': 0.001, 'EPOCHS': 25}\n",
      "Best model found with loss:  6.251648821801949e-05\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Best Hyperparameters:  {'layers': 2, 'cells': 16, 'seq_len': 10, 'batch_size': 8, 'stateful': [True], 'LR': 0.01, 'EPOCHS': 25}\n",
      "Best model found with loss:  6.243665015421905e-05\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Best Hyperparameters:  {'layers': 2, 'cells': 16, 'seq_len': 10, 'batch_size': 8, 'stateful': [True], 'LR': 0.001, 'EPOCHS': 25}\n",
      "Best model found with loss:  6.037906626157822e-05\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Best Hyperparameters:  {'layers': 2, 'cells': 16, 'seq_len': 10, 'batch_size': 8, 'stateful': [True], 'LR': 0.01, 'EPOCHS': 25}\n",
      "Best model found with loss:  6.024153015910969e-05\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Best Hyperparameters:  {'layers': 2, 'cells': 16, 'seq_len': 10, 'batch_size': 8, 'stateful': [True], 'LR': 0.5, 'EPOCHS': 25}\n",
      "Best model found with loss:  6.0231592282395044e-05\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 16 LSTM cells,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Best Hyperparameters:  {'layers': 2, 'cells': 32, 'seq_len': 10, 'batch_size': 8, 'stateful': [True], 'LR': 0.001, 'EPOCHS': 25}\n",
      "Best model found with loss:  5.967974540034817e-05\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Best Hyperparameters:  {'layers': 2, 'cells': 32, 'seq_len': 10, 'batch_size': 8, 'stateful': [True], 'LR': 0.001, 'EPOCHS': 50}\n",
      "Best model found with loss:  5.146363105212862e-05\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Best Hyperparameters:  {'layers': 2, 'cells': 32, 'seq_len': 10, 'batch_size': 8, 'stateful': [True], 'LR': 0.01, 'EPOCHS': 50}\n",
      "Best model found with loss:  5.143869794178594e-05\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Best Hyperparameters:  {'layers': 2, 'cells': 32, 'seq_len': 10, 'batch_size': 8, 'stateful': [True], 'LR': 0.5, 'EPOCHS': 50}\n",
      "Best model found with loss:  5.1336410625123284e-05\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Best Hyperparameters:  {'layers': 2, 'cells': 32, 'seq_len': 10, 'batch_size': 8, 'stateful': [True], 'LR': 0.001, 'EPOCHS': 25}\n",
      "Best model found with loss:  4.885181165106735e-05\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 32 LSTM cells,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Best Hyperparameters:  {'layers': 2, 'cells': 48, 'seq_len': 10, 'batch_size': 8, 'stateful': [True], 'LR': 0.001, 'EPOCHS': 25}\n",
      "Best model found with loss:  4.495841413996909e-05\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Best Hyperparameters:  {'layers': 2, 'cells': 48, 'seq_len': 10, 'batch_size': 8, 'stateful': [True], 'LR': 0.01, 'EPOCHS': 25}\n",
      "Best model found with loss:  4.4805773146212534e-05\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 48 LSTM cells,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 64 LSTM cells,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 80 LSTM cells,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 96 LSTM cells,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 48 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 64 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 80 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 96 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells, 112 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 2 layers, 112 LSTM cells,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 16 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 64 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 80 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 96 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 112 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 32 LSTM cells 2, 8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 16 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 32 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.001, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.01, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 25, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 50, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 75, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.1, epochs = 100, seq_len = 10\n",
      "Training LSTM model with 3 layers, 16 LSTM cells, 48 LSTM cells 2, 48 LSTM cells 3,  8 batch size, LR = 0.5, epochs = 25, seq_len = 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1079963/1542658044.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Hyperparameter Optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m best_model, best_hyperparameters = hyperparameter_optimization(hyperparameters = hyperparameters,\n\u001b[0m\u001b[1;32m     29\u001b[0m                                                                 \u001b[0mNUM_FEATS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_FEATS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                                                 NUM_OUTPUTS = NUM_OUTPUTS)\n",
      "\u001b[0;32m/tmp/ipykernel_1079963/1931613647.py\u001b[0m in \u001b[0;36mhyperparameter_optimization\u001b[0;34m(hyperparameters, NUM_FEATS, NUM_OUTPUTS)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                                     \u001b[0;31m# Select best model based on testing loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                                     Y_pred = test_model_per_trajectory(mdl = model_sl1, \n\u001b[0m\u001b[1;32m     84\u001b[0m                                                                         \u001b[0mX_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                                                                         \u001b[0mtest_traj_seq_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_traj_seq_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1079963/3549368543.py\u001b[0m in \u001b[0;36mtest_model_per_trajectory\u001b[0;34m(mdl, X_t, test_traj_seq_lengths, SEQ_LENGTH, NUM_FEATS)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_FEATS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_traj_seq_lengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mY_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/traj_exp/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/traj_exp/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/traj_exp/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/traj_exp/venv/lib/python3.10/site-packages/keras/src/trainers/epoch_iterator.py\u001b[0m in \u001b[0;36m_enumerate_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_seen\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/traj_exp/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
      "\u001b[0;32m~/traj_exp/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 709\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/traj_exp/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    746\u001b[0m             self._flat_output_types)\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_set_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/traj_exp/venv/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3476\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3479\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3480\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameter Optimization\n",
    "\n",
    "# Hyperparameter ranges\n",
    "\n",
    "LAYERS = [2, 3]\n",
    "CELLS = list(range(16, 128, 16)) #[16, 32, 48, 64, 128]\n",
    "CELLS_L2 = list(range(16, 128, 16))\n",
    "CELLS_L3 = list(range(16, 128, 16))\n",
    "SEQ_LEN_RANGE = [10, 20, 30, 40, 50]\n",
    "BATCH_SIZE_RANGE = [8, 16, 32, 64, 128]\n",
    "STATEFUL_RANGE = [True]\n",
    "LR_RANGE = [0.001, 0.01, 0.1, 0.5]\n",
    "EPOCHS_RANGE = [25, 50, 75, 100]\n",
    "\n",
    "hyperparameters = {\n",
    "    \"LAYERS\": LAYERS,\n",
    "    \"cells\": CELLS,\n",
    "    \"seq_len\": SEQ_LEN_RANGE,\n",
    "    \"batch_size\": BATCH_SIZE_RANGE,\n",
    "    \"stateful\": STATEFUL_RANGE,\n",
    "    \"LR\": LR_RANGE,\n",
    "    \"EPOCHS\": EPOCHS_RANGE,\n",
    "}\n",
    "\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "\n",
    "best_model, best_hyperparameters = hyperparameter_optimization(hyperparameters = hyperparameters,\n",
    "                                                                NUM_FEATS = NUM_FEATS,\n",
    "                                                                NUM_OUTPUTS = NUM_OUTPUTS)\n",
    "\n",
    "print(best_hyperparameters)\n",
    "print(best_model.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
